
Minimal Implementation of  [``A watermark for Large Language Models``](https://arxiv.org/pdf/2301.10226.pdf)



#### Details of Algorithm 2: Text Generation with Soft Red List 

Input:
- $s^{(−Np)} \ldots s^{-1}$ prompt of length $N_p$
- $\gamma \in(0,1)$ `green list size`
- $\delta > 0$  `hardness parameter`

Output:  
- $s^{(0)} \ldots s^{(T)}$ token generated by language model.

**for** $ t = 0,1, \ldots $ **do**
1. Apply the language model to prior tokens $ s^{(−Np)} \ldots s^{(t-1)}$  to get a logit vector $l^{(t)} $ over the vocabulary.
2. Compute a hash of token $s^{(t-1)}$.  
Use it to seed a RNG.
3. Using this RNG, randomly partition the vocabulary into:  
a **green list** $G$ of size $ \gamma |V| $ and  
a **red list** $R$ of size $ (1−\gamma)|V| $
4. Add $\delta$ to each green list logit.   
Apply the softmax operator to these modified logits to get a probability distribution over the vocabulary.  
$\hat{p}_{k}^{(t)} = 
\left\{ 
    \begin{array} {rcl}
    \frac
        { \exp ( l^{(t)}_k  + \delta)}
        {\sum_{i\in R} \exp (l^{(t)}_i) + \sum_{i\in G} \exp ( l^{(t)}_i + \delta)},
    & k \in G \\
    \frac
        { \exp ( l^{(t)}_k)}
        {\sum_{i\in R} \exp (l^{(t)}_i) + \sum_{i\in G} \exp ( l^{(t)}_i + \delta)},
    & k \in R
   \end{array} 
\right\}$
5. Sample the next token, $s^{(t)}$ , using the water-marked distribution $\hat{p}^{(t)}$.


#### Detecting Watermarks:
  
Null Hypothesis $H_0:$ The text sequence is generated w/ no knowledge if the red list rule.  
The number of green list tokens, denoted $|s|_G$ has expected value $T/2$ and variance $T/4$.  
For a One proportion z-test the z-statistic is  :
$$z = \frac{2(|s|_G - T/2)}{\sqrt{T}}$$
for an arbitrary $\gamma$, $$z = \frac{(|s|_G - \gamma T)}{\sqrt{T \gamma (1 - \gamma)}}$$


### Usage:
```
# Generate without watermark
python driver.py --user_prompt "Write a 8-liner poetry about PCIe." --watermark False --gif_dest_path temp/

# Generate with Hard Red List watermarking rule.
python driver.py --user_prompt "Write a 8-liner poetry about PCIe." --watermark True --watermark_mode hard --gif_dest_path temp/

# Generate with Soft Red List watermarking rule, and low hardness.
python driver.py --user_prompt "Write a 8-liner poetry about PCIe." --watermark True --watermark_mode soft --hardness 2.0 --gif_dest_path temp/

#Generate with Soft Red List watermarking rule, and higher hardness.
python driver.py --user_prompt "Write a 8-liner poetry about PCIe." --watermark True --watermark_mode soft --hardness 4.0 --gif_dest_path temp/
```


### Module Usage:

```
from watermark import WaterMark, WaterMarkConfig, WaterMarkDetector, wmGenerate

model = ...       # some huggingface language model
tokenizer = ...   # huggingface tokenizer

wm_cfg = WaterMarkConfig(vocab_size=tokenizer.vocab_size, device=model.device)
```
set hard red list or soft red list 
```
wm_cfg.soft_mode = True         # False for hard red list

watermarker = WaterMark(wm_cfg)
wm_detector = WaterMarkDetector(wm_cfg)

user_prompt = 'write a 8 liner poetry about tensors.'

prompt_ids, wm_output_ids = wmGenerate(
        model=model, 
        tokenizer=tokenizer, 
        prompt=prompt, 
        watermarker=watermarker, 
        max_length = 250,
        temperature = 0.7,
        do_sample = True)

prompt = tokenizer.decode(prompt_ids.squeeze(0), skip_special_tokens=True)
non_wm_gens = tokenizer.decode(output_ids.squeeze(0), skip_special_tokens=True)
```

detection
```
stats = wm_detector.detect(prompt, wm_gens, tokenizer)
```


python driver.py --user_prompt "Write a 8-liner poetry about PCIe." --watermark False --gif_dest_path temp/

python driver.py --user_prompt "Write a 8-liner poetry about PCIe." --watermark True --watermark_mode hard --gif_dest_path temp/

python driver.py --user_prompt "Write a 8-liner poetry about PCIe." --watermark True --watermark_mode soft --hardness 2.0 --gif_dest_path temp/

python driver.py --user_prompt "Write a 8-liner poetry about PCIe." --watermark True --watermark_mode soft --hardness 4.0 --gif_dest_path temp/

